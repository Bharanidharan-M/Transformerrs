{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQxBldvnQBBh/9Uf/DICEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bharanidharan-M/Transformerrs/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmYNRw14XFS2"
      },
      "outputs": [],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier=pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "classifier(\"This is the best day in my life\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW8OrLIzXMD4",
        "outputId": "ef6178ca-5263-47f4-b2d8-10e6710c58cd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998595714569092}]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\n",
        "    ['I have been waiting for a Huggingface course my whole life','Today I am so tired']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGYCv7fQXpln",
        "outputId": "448df383-f246-41bb-bdb5-a8592a9f5fa2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9450720548629761},\n",
              " {'label': 'NEGATIVE', 'score': 0.9997604489326477}]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier=pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"I am working on my new project\"\n",
        ",candidate_labels=[\"education\",\"politics\",\"business\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snwH6nFrYNr-",
        "outputId": "dc07136d-ac42-4253-9d99-321a1b61f28f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'I am working on my new project',\n",
              " 'labels': ['business', 'education', 'politics'],\n",
              " 'scores': [0.7514903545379639, 0.1651148498058319, 0.08339477330446243]}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator=pipeline(\"text-generation\")\n",
        "generator(\"Today climate is good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxKOArF1ZDwM",
        "outputId": "d502fdb1-56b5-43ee-d391-cdf0bdf2c841"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Today climate is good for agriculture. We have a huge opportunity to develop smart agriculture solutions that will reduce greenhouse gas emissions,\" said Stephen Cancie, Vice President of Agriculture, Department of Agriculture.\\n\\nThe Climate Action Plan was developed by the Department of Agriculture, Office of the Secretary for the Environment, Office of Management and Budget, Office of the Director for Resources, and Assistant Secretary of Agriculture for Climate Change, Office of Management and Budget. The plan is available for download at https://www.daa.gov/climate-action-plan/climate-action-plan-final.pdf. The report is available online at http://www.daa.gov/bio/climate-action-plan.pdf.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\")"
      ],
      "metadata": {
        "id": "M7qro6oaZdak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")"
      ],
      "metadata": {
        "id": "Ka_pkls5aUkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "unmasker=pipeline(\"fill-mask\")\n",
        "unmasker(\"Today climate is good<mask>\",top_k=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzhvfHbPhgt8",
        "outputId": "4dfe2c66-31b3-4791-9171-a3d6c002fe5a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.48678070306777954,\n",
              "  'token': 72,\n",
              "  'token_str': '.\"',\n",
              "  'sequence': 'Today climate is good.\"'},\n",
              " {'score': 0.1302953064441681,\n",
              "  'token': 4,\n",
              "  'token_str': '.',\n",
              "  'sequence': 'Today climate is good.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner=pipeline(\"ner\",grouped_entities=True)\n",
        "ner(\"my name is sylvain and i work at huuging face brooklyn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkp4l5zph4AN",
        "outputId": "0a2f9caf-8c50-4432-8d37-45982047b22e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:181: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9888104),\n",
              "  'word': 'sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_answering=pipeline(\"question-answering\")\n",
        "question_answering(\n",
        "    question=\"Which countries does the Nile flow through?\",\n",
        "    context=\"The Nile is the longest river in the world. It flows through several countries including Uganda, Sudan, and Egypt. The river plays a major role in supporting agriculture and livelihoods in the region.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGdnEkt6iXYV",
        "outputId": "f78c1e00-b3a4-4aa1-e588-1ce57e30b159"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9469901323318481,\n",
              " 'start': 89,\n",
              " 'end': 113,\n",
              " 'answer': 'Uganda, Sudan, and Egypt'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\")\n",
        "text = \"\"\"\n",
        "Artificial intelligence (AI) is the simulation of human intelligence processes by machines,\n",
        "especially computer systems. These processes include learning, reasoning, and self-correction.\n",
        "AI is being used in various applications, including expert systems, natural language processing (NLP),\n",
        "speech recognition, and machine vision. AI systems are powered by algorithms, using techniques\n",
        "such as machine learning and deep learning to demonstrate 'intelligent' behavior.\n",
        "\"\"\"\n",
        "summary = summarizer(text, max_length=40, min_length=10, do_sample=False)\n",
        "print(summary[0]['summary_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXmox3iBjwoE",
        "outputId": "1bb3e25a-92dd-4ef4-a044-cf7532585e4e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Artificial intelligence (AI) is being used in various applications, including expert systems, natural language processing (NLP) and machine vision . AI systems are powered by algorithms, using techniques \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
        "output = translator(\"translate English to French: How are you?\", max_length=40)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSKv2Oe3j9Fx",
        "outputId": "3f660445-29c9-4720-e937-226aeb862ecd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment êtes-vous?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
        "import torch"
      ],
      "metadata": {
        "id": "wXJT_Y90pAOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "model=AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
      ],
      "metadata": {
        "id": "2R_kGzjXpMq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"I love this!\""
      ],
      "metadata": {
        "id": "IIZjk07Lps5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=tokenizer(sentence,return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "8bVC6T4jp4gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=model(**inputs)\n",
        "probabilities=torch.softmax(outputs.logits,dim=1)"
      ],
      "metadata": {
        "id": "y8o_PWNeqCZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcA_dte5qQpP",
        "outputId": "26f5e689-a19e-40b1-da94-78aae3c7b950"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2351e-04, 9.9988e-01]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_id=torch.argmax(probabilities).item()\n",
        "label=model.config.id2label[label_id]"
      ],
      "metadata": {
        "id": "IMsCwJ-uqRDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_id"
      ],
      "metadata": {
        "id": "lUaO0GjNqRTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sentence:{sentence}\")\n",
        "print(f\"Sentiment:{label}\")\n",
        "print(f\"Probabilities:{probabilities.tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWeg8Js2qyXE",
        "outputId": "da7a6457-38a2-472f-d438-cc9790848191"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:I love this!\n",
            "Sentiment:POSITIVE\n",
            "Probabilities:[[0.0001235113595612347, 0.9998764991760254]]\n"
          ]
        }
      ]
    }
  ]
}